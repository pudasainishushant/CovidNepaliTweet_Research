{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d8adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08f3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/fm-pc-lt-228/Desktop/covid_nepali_tweets/covid19_tweeter_dataset (copy).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c822dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tokanize_tweet</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-01-10 22:06:41+00:00</td>\n",
       "      <td>अमेरिकामा कोभिड बाट एकै दिन चार हजारभन्दा बढीक...</td>\n",
       "      <td>अमेरिकामा,कोभिड,बाट,एकै,दिन,चार,हजारभन्दा,बढीक...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-01-10 17:49:34+00:00</td>\n",
       "      <td>कोभिड का कारण विदेशमा रहेका नेपालीहरुमा मानसिक...</td>\n",
       "      <td>कोभिड,का,कारण,विदेशमा,रहेका,नेपालीहरुमा,मानसिक...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-10 16:18:34+00:00</td>\n",
       "      <td>नेपालमा क्लोभर बायोफार्मास्युटिकल्स अस्ट्रेलिय...</td>\n",
       "      <td>नेपालमा,क्लोभर,बायोफार्मास्युटिकल्स,अस्ट्रेलिय...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-10 15:12:17+00:00</td>\n",
       "      <td>कोभिड को खोप पनि लगाइयो</td>\n",
       "      <td>कोभिड,को,खोप,पनि,लगाइयो</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-01-10 15:07:12+00:00</td>\n",
       "      <td>अमेरिकामा कोभिड को नयाँ रेकर्ड एकै दिन हजारभन्...</td>\n",
       "      <td>अमेरिकामा,कोभिड,को,नयाँ,रेकर्ड,एकै,दिन,हजारभन्...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35395</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1238</td>\n",
       "      <td>यसरी त म २० पन्ना भएनी देखाउछु उत्ता गएर फोनमा...</td>\n",
       "      <td>कोभिड,यत्रो,जोखिम,त्रास,हुॅदा,प्रदेश,स्थानीय,स...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35396</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1239</td>\n",
       "      <td>बजारमा भित्रिए नयाँ Bijaya Shahi शाही, बल्ल सा...</td>\n",
       "      <td>बर्षिय,स्पेनिस,फुटबल,कोचको,कोभिड,संक्रमणबाट,मृ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35397</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1240</td>\n",
       "      <td>कसो हो</td>\n",
       "      <td>भरतपुर,महानगरपालिका,चितवन,प्रदर्शनी,केन्द्रमा,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1241</td>\n",
       "      <td>अबो यो मिडिया पनि सिदिने भो हहह</td>\n",
       "      <td>कोरोना,भाईरस,कोभिड,आयरल्याण्ड,क्रिकेट,टिमको,जि...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35399</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1242</td>\n",
       "      <td>य उहाँ मेमरी किङ्ग पो ho</td>\n",
       "      <td>एकाएक,कोभिड,फलो,गरेछ,सक्कली,अहिलेसम्म,नेपाल,सक...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35400 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Label                   Datetime  \\\n",
       "0             0.0     -1  2021-01-10 22:06:41+00:00   \n",
       "1             1.0     -1  2021-01-10 17:49:34+00:00   \n",
       "2             2.0      1  2021-01-10 16:18:34+00:00   \n",
       "3             3.0      0  2021-01-10 15:12:17+00:00   \n",
       "4             4.0     -1  2021-01-10 15:07:12+00:00   \n",
       "...           ...    ...                        ...   \n",
       "35395         NaN      0                       1238   \n",
       "35396         NaN      0                       1239   \n",
       "35397         NaN      0                       1240   \n",
       "35398         NaN      0                       1241   \n",
       "35399         NaN      0                       1242   \n",
       "\n",
       "                                                   Tweet  \\\n",
       "0      अमेरिकामा कोभिड बाट एकै दिन चार हजारभन्दा बढीक...   \n",
       "1      कोभिड का कारण विदेशमा रहेका नेपालीहरुमा मानसिक...   \n",
       "2      नेपालमा क्लोभर बायोफार्मास्युटिकल्स अस्ट्रेलिय...   \n",
       "3                                कोभिड को खोप पनि लगाइयो   \n",
       "4      अमेरिकामा कोभिड को नयाँ रेकर्ड एकै दिन हजारभन्...   \n",
       "...                                                  ...   \n",
       "35395  यसरी त म २० पन्ना भएनी देखाउछु उत्ता गएर फोनमा...   \n",
       "35396  बजारमा भित्रिए नयाँ Bijaya Shahi शाही, बल्ल सा...   \n",
       "35397                                             कसो हो   \n",
       "35398                    अबो यो मिडिया पनि सिदिने भो हहह   \n",
       "35399                           य उहाँ मेमरी किङ्ग पो ho   \n",
       "\n",
       "                                          Tokanize_tweet Unnamed: 5  \n",
       "0      अमेरिकामा,कोभिड,बाट,एकै,दिन,चार,हजारभन्दा,बढीक...        NaN  \n",
       "1      कोभिड,का,कारण,विदेशमा,रहेका,नेपालीहरुमा,मानसिक...        NaN  \n",
       "2      नेपालमा,क्लोभर,बायोफार्मास्युटिकल्स,अस्ट्रेलिय...        NaN  \n",
       "3                                कोभिड,को,खोप,पनि,लगाइयो        NaN  \n",
       "4      अमेरिकामा,कोभिड,को,नयाँ,रेकर्ड,एकै,दिन,हजारभन्...        NaN  \n",
       "...                                                  ...        ...  \n",
       "35395  कोभिड,यत्रो,जोखिम,त्रास,हुॅदा,प्रदेश,स्थानीय,स...        NaN  \n",
       "35396  बर्षिय,स्पेनिस,फुटबल,कोचको,कोभिड,संक्रमणबाट,मृ...        NaN  \n",
       "35397  भरतपुर,महानगरपालिका,चितवन,प्रदर्शनी,केन्द्रमा,...        NaN  \n",
       "35398  कोरोना,भाईरस,कोभिड,आयरल्याण्ड,क्रिकेट,टिमको,जि...        NaN  \n",
       "35399  एकाएक,कोभिड,फलो,गरेछ,सक्कली,अहिलेसम्म,नेपाल,सक...        NaN  \n",
       "\n",
       "[35400 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2411ec71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'प्रधानमँत्रीज्यू चुनाव गर्ने पैसा हुने तर कोभीड बाट जनताको लागि निशूल्क खोप ल्याउन पैसा नहुने खोप ल्याउन किन ढिलाइ गरिँदैछ देश र जनताप्रति किन लापरबाही'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tweet'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d04891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length'] = data['Tokanize_tweet'].apply(\n",
    "    lambda row: min(len(row.split(\",\")), len(row)) if isinstance(row, str) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8922dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(data['length'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed98d659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'कोभिड का कारण विदेशमा रहेका नेपालीहरुमा मानसिक स्वास्थ्य सम्बन्धि समस्या देखिएको र आत्महत्याका घटनाहरु बढेको डा सापकोटाले बताए'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tweet\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177b8fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tokanize_tweet</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-01-10 22:06:41+00:00</td>\n",
       "      <td>अमेरिकामा कोभिड बाट एकै दिन चार हजारभन्दा बढीक...</td>\n",
       "      <td>अमेरिकामा,कोभिड,बाट,एकै,दिन,चार,हजारभन्दा,बढीक...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-01-10 17:49:34+00:00</td>\n",
       "      <td>कोभिड का कारण विदेशमा रहेका नेपालीहरुमा मानसिक...</td>\n",
       "      <td>कोभिड,का,कारण,विदेशमा,रहेका,नेपालीहरुमा,मानसिक...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-10 16:18:34+00:00</td>\n",
       "      <td>नेपालमा क्लोभर बायोफार्मास्युटिकल्स अस्ट्रेलिय...</td>\n",
       "      <td>नेपालमा,क्लोभर,बायोफार्मास्युटिकल्स,अस्ट्रेलिय...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-10 15:12:17+00:00</td>\n",
       "      <td>कोभिड को खोप पनि लगाइयो</td>\n",
       "      <td>कोभिड,को,खोप,पनि,लगाइयो</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2021-01-10 15:07:12+00:00</td>\n",
       "      <td>अमेरिकामा कोभिड को नयाँ रेकर्ड एकै दिन हजारभन्...</td>\n",
       "      <td>अमेरिकामा,कोभिड,को,नयाँ,रेकर्ड,एकै,दिन,हजारभन्...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Label                   Datetime  \\\n",
       "0         0.0     -1  2021-01-10 22:06:41+00:00   \n",
       "1         1.0     -1  2021-01-10 17:49:34+00:00   \n",
       "2         2.0      1  2021-01-10 16:18:34+00:00   \n",
       "3         3.0      0  2021-01-10 15:12:17+00:00   \n",
       "4         4.0     -1  2021-01-10 15:07:12+00:00   \n",
       "\n",
       "                                               Tweet  \\\n",
       "0  अमेरिकामा कोभिड बाट एकै दिन चार हजारभन्दा बढीक...   \n",
       "1  कोभिड का कारण विदेशमा रहेका नेपालीहरुमा मानसिक...   \n",
       "2  नेपालमा क्लोभर बायोफार्मास्युटिकल्स अस्ट्रेलिय...   \n",
       "3                            कोभिड को खोप पनि लगाइयो   \n",
       "4  अमेरिकामा कोभिड को नयाँ रेकर्ड एकै दिन हजारभन्...   \n",
       "\n",
       "                                      Tokanize_tweet Unnamed: 5  length  \n",
       "0  अमेरिकामा,कोभिड,बाट,एकै,दिन,चार,हजारभन्दा,बढीक...        NaN     9.0  \n",
       "1  कोभिड,का,कारण,विदेशमा,रहेका,नेपालीहरुमा,मानसिक...        NaN    18.0  \n",
       "2  नेपालमा,क्लोभर,बायोफार्मास्युटिकल्स,अस्ट्रेलिय...        NaN    20.0  \n",
       "3                            कोभिड,को,खोप,पनि,लगाइयो        NaN     5.0  \n",
       "4  अमेरिकामा,कोभिड,को,नयाँ,रेकर्ड,एकै,दिन,हजारभन्...        NaN    12.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2464feae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'कोभिड,का,कारण,विदेशमा,रहेका,नेपालीहरुमा,मानसिक,स्वास्थ्य,सम्बन्धि,समस्या,देखिएको,र,आत्महत्याका,घटनाहरु,बढेको,डा,सापकोटाले,बताए'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tokanize_tweet\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18969988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    14998\n",
       "-1    13606\n",
       " 0     6796\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce0c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoTokenizer, AutoModelForMaskedLM\n",
    "from scipy.spatial.distance import cosine \n",
    "import tokenizers \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import snowballstemmer\n",
    "import numpy\n",
    "import os \n",
    "import re\n",
    "import json\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b519b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"Shushant/nepaliBERT\", output_hidden_states = True, return_dict = True, output_attentions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc414c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = AutoTokenizer.from_pretrained(\"Shushant/nepaliBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1a612",
   "metadata": {},
   "source": [
    "pickle.dump(model, open('bert_embeddings','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9b5da",
   "metadata": {},
   "source": [
    "pickle.dump(tokenizers, open('bert_tokenizers','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e3242f",
   "metadata": {},
   "source": [
    "model = pickle.load(open('bert_embeddings','rb'))\n",
    "tokenizers= pickle.load(open('bert_tokenizers','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1871cd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['क',\n",
       " 'मौ',\n",
       " '##ज',\n",
       " '##दा',\n",
       " 'लोक',\n",
       " '##तान',\n",
       " '##तर',\n",
       " '##िक',\n",
       " 'वय',\n",
       " '##वस',\n",
       " '##था',\n",
       " 'राज',\n",
       " '##य',\n",
       " 'पन',\n",
       " '##ः',\n",
       " '##सर',\n",
       " '##चना',\n",
       " '##सग',\n",
       " 'जोडिएका',\n",
       " 'हिजोका',\n",
       " 'सवाल',\n",
       " '##हर',\n",
       " '##लाई',\n",
       " 'यथा',\n",
       " '##स',\n",
       " '##थिति',\n",
       " '##मा',\n",
       " 'छोड',\n",
       " '##र',\n",
       " 'सबल',\n",
       " 'होला',\n",
       " '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers.tokenize(\"के मौजुदा लोकतान्त्रिक व्यवस्था राज्य पुनःसंरचनासँग जोडिएका हिजोका सवालहरूलाई यथास्थितिमा छोडेर सबल होला?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08820a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding_sentence(input_sentence):\n",
    "    md = model\n",
    "    tokenizer = tokenizers\n",
    "#     md = local_model\n",
    "#     tokenizer = local_tokenizers\n",
    "    marked_text = \" [CLS] \" + input_sentence + \" [SEP] \"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(indexed_tokens) \n",
    "    \n",
    "    # Convert inputs to Pytorch tensors\n",
    "    tokens_tensors = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = md(tokens_tensors, segments_tensors)\n",
    "        # removing the first hidden state\n",
    "        # the first state is the input state \n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "#         print(hidden_states[-2])\n",
    "        # second_hidden_states = outputs[2]\n",
    "    # hidden_states has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "    # token_vecs is a tensor with shape [22 x 768]\n",
    "#     token_vecs = hidden_states[-2][0]\n",
    "    # get last four layers\n",
    "#     last_four_layers = [hidden_states[i] for i in (-1,-2, -3,-4)]\n",
    "    # cast layers to a tuple and concatenate over the last dimension\n",
    "#     cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "#     print(cat_hidden_states.shape)\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    # take the mean of the concatenated vector over the token dimension\n",
    "#     sentence_embedding = torch.mean(cat_hidden_states, dim=0).squeeze()\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "#     sentence_embedding = torch.mean(token_vecs, dim=1)\n",
    "    return sentence_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c810fd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अमेरिकामा कोभिड बाट एकै दिन चार हजारभन्दा बढीको मृत्यु'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tweet\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a1a2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_embeddings'] = data['Tweet'].apply(get_bert_embedding_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a2f55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"embeddings_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16889493",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data['word_embeddings'], data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fad91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a560a",
   "metadata": {},
   "source": [
    "train_df,test_df = train_test_split(data, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4a917",
   "metadata": {},
   "source": [
    "train_df.to_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbff085",
   "metadata": {},
   "source": [
    "test_df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f706ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba420c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(train_X.tolist(), train_y)\n",
    "#svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a4c4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(test_X.tolist())\n",
    "# svc_pred = svc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf9e1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2232   53  441]\n",
      " [ 318  304  455]\n",
      " [ 511   52 2466]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "614ae1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.82      0.77      2726\n",
      "           0       0.74      0.28      0.41      1077\n",
      "           1       0.73      0.81      0.77      3029\n",
      "\n",
      "    accuracy                           0.73      6832\n",
      "   macro avg       0.74      0.64      0.65      6832\n",
      "weighted avg       0.73      0.73      0.71      6832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4359624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7321428571428571"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, svc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"नराम्रो\"\n",
    "predicted_label = svc.predict_proba(np.array(get_bert_embedding_sentence(sent).tolist()).reshape(1,-1))[0]\n",
    "if predicted_label[0]<predicted_label[1]:\n",
    "    print(f'{sent} is negative sentiment')\n",
    "else:\n",
    "    print(f'{sent} is positive sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5835169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6766243465272591"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0).fit(train_X.tolist(), train_y)\n",
    "gbc.score(test_X.tolist(), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5270babe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7047050037341299"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(train_X.tolist(), train_y)\n",
    "\n",
    "\n",
    "\n",
    "clf.score(test_X.tolist(), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a5e954f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5870052277819268"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_X.tolist(), train_y)\n",
    "gnb.score(test_X.tolist(), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6c4381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1491  599  666]\n",
      " [ 124  473  387]\n",
      " [ 336  653 1966]]\n"
     ]
    }
   ],
   "source": [
    "gnb_pred = gnb.predict(test_X.tolist())\n",
    "print(confusion_matrix(test_y, gnb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957caa2c",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b3b7e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 16:15:27.659036: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-19 16:15:27.682787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-19 16:15:27.682799: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7883dc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.05079815e-01,  6.60110891e-01,  3.57779235e-01,  9.07263815e-01,\n",
       "        1.11969285e-01, -2.28671238e-01, -8.88476148e-02, -6.83927462e-02,\n",
       "        1.48592234e-01, -1.53660014e-01,  1.89314857e-01,  2.41184011e-01,\n",
       "        2.40040213e-01, -2.35330522e-01, -8.25594515e-02,  4.54757750e-01,\n",
       "        3.78678322e-01, -4.91710782e-01, -5.43783940e-02, -2.33931094e-01,\n",
       "        2.94030815e-01, -4.41250712e-01, -2.24258199e-01, -3.41822237e-01,\n",
       "       -5.49264014e-01, -8.49143922e-01,  5.85750163e-01,  2.20755696e-01,\n",
       "       -4.64857101e-01,  4.92242128e-01, -5.72632104e-02, -5.02846576e-02,\n",
       "        3.37019265e-02, -4.17852759e-01,  1.03762947e-01, -4.72780734e-01,\n",
       "       -3.54295187e-02,  3.08029979e-01,  1.62414331e-02,  2.00192213e-01,\n",
       "        4.00807559e-01, -4.75480258e-01,  2.34706059e-01, -1.67396903e-01,\n",
       "        2.97297001e-01,  4.75440264e-01, -4.63157415e-01,  2.17456490e-01,\n",
       "       -1.44426808e-01, -1.16206385e-01, -2.52778262e-01, -1.54680514e+00,\n",
       "        3.75086218e-02,  3.61103803e-01, -6.98884487e-01, -1.66491464e-01,\n",
       "        7.01895962e-03, -1.88809082e-01,  6.59896076e-01, -2.43993446e-01,\n",
       "       -2.89669901e-01,  1.31559566e-01, -3.28882970e-02, -1.28968596e-01,\n",
       "        1.49198622e-01, -1.89175740e-01, -2.65256822e-01, -6.31871298e-02,\n",
       "        3.61595988e-01, -2.95051545e-01, -3.13606232e-01,  3.19071054e-01,\n",
       "        2.21488029e-01, -6.35387152e-02, -2.60682255e-01,  6.65526688e-01,\n",
       "        2.47929186e-01,  1.37082590e-02,  2.45270252e-01, -4.97984320e-01,\n",
       "        1.40538663e-01,  1.12402454e-01, -2.43089959e-01,  2.39361152e-01,\n",
       "       -7.86796153e-01,  3.26587319e-01, -1.76275969e-01,  4.92420435e-01,\n",
       "        8.01470950e-02, -7.54217207e-01, -1.36657327e-01,  2.00079411e-01,\n",
       "        8.35955739e-02, -1.61427826e-01, -5.61474077e-02,  6.26202067e-03,\n",
       "       -3.67157370e-01, -1.12311877e-01, -6.56742930e-01, -3.73857439e-01,\n",
       "       -2.49094851e-02,  7.58914232e-01, -2.21286744e-01, -4.31436718e-01,\n",
       "       -1.58550799e-01,  7.15919724e-03,  3.26035798e-01, -2.67145246e-01,\n",
       "       -2.32933741e-02,  3.27322572e-01,  4.60631043e-01,  3.03725243e-01,\n",
       "        2.72502787e-02,  1.67246476e-01,  1.61377937e-01,  1.27298981e-02,\n",
       "        3.04317504e-01,  5.24225235e-01, -9.63555396e-01,  3.54525559e-02,\n",
       "       -9.53734145e-02, -3.35769951e-01,  4.13959295e-01, -1.62638694e-01,\n",
       "       -2.76970536e-01, -2.23042384e-01,  8.02862793e-02, -4.17919248e-01,\n",
       "       -3.76422197e-01, -4.16185915e-01,  2.71082204e-02, -7.68173784e-02,\n",
       "       -2.08283961e-01,  5.12339592e-01,  2.15562075e-01,  1.67669319e-02,\n",
       "        6.14894032e-01, -1.54938856e-02, -3.85128930e-02,  2.98934057e-02,\n",
       "        2.20871589e-04,  1.50487155e-01,  1.54266977e+00,  5.07266939e-01,\n",
       "       -1.42631829e-02,  3.04844558e-01,  9.01346467e-03, -4.61358309e-01,\n",
       "       -3.80339205e-01, -2.67259955e-01,  3.71954203e-01,  4.79900427e-02,\n",
       "       -7.97203302e-01, -1.15718916e-02,  8.28313641e-03,  1.44067004e-01,\n",
       "       -5.16858160e-01, -1.68859541e-01,  2.08438307e-01, -7.32257545e-01,\n",
       "        5.16338885e-01, -3.41768265e-02,  5.77232335e-03, -3.55722547e-01,\n",
       "       -6.69220030e-01,  1.68089405e-01,  4.41470921e-01, -4.71816629e-01,\n",
       "        3.46057624e-01,  1.40605986e-01,  1.04227751e-01,  3.59039336e-01,\n",
       "       -1.93849832e-01, -6.89546689e-02,  2.89705783e-01,  2.26600438e-01,\n",
       "        2.71112382e-01, -4.50823568e-02,  4.77538824e-01, -5.73125184e-01,\n",
       "        2.18207270e-01, -4.53779519e-01,  1.22428335e-01,  4.31397781e-02,\n",
       "        4.24774617e-01,  1.97072119e-01, -2.12968811e-01,  3.67918521e-01,\n",
       "        6.39768243e-02, -1.62244469e-01, -1.39608473e-01,  1.40716925e-01,\n",
       "       -4.79596823e-01, -1.04394279e-01,  8.90616328e-02, -1.21671073e-01,\n",
       "       -1.01587638e-01, -1.43657342e-01,  1.79998666e-01,  8.19939896e-02,\n",
       "       -1.60966888e-01, -2.89744616e-01, -6.86138153e-01, -5.10720387e-02,\n",
       "       -1.69235215e-01, -4.02659178e-01, -1.85233876e-01, -8.05030406e-01,\n",
       "        1.87231712e-02, -1.99214667e-01, -2.69409746e-01,  7.91369230e-02,\n",
       "        9.41775739e-03, -1.75213948e-01, -7.70678818e-02, -8.63552392e-01,\n",
       "       -1.56568646e-01,  4.16238666e-01,  1.26474217e-01, -4.72095221e-01,\n",
       "        2.59007543e-01,  4.34776256e-03, -2.23010525e-01,  5.53479530e-02,\n",
       "       -5.38477898e-01,  4.45801318e-01,  2.19545230e-01, -2.69146681e-01,\n",
       "        2.28348181e-01,  3.78167033e-01, -1.64056450e-01,  2.41970703e-01,\n",
       "       -5.47031164e-01, -3.08718115e-01, -5.79038262e-02,  2.35905871e-01,\n",
       "       -4.29084748e-02,  2.80414015e-01,  1.60383135e-01, -3.61086071e-01,\n",
       "       -8.50843266e-02,  3.03882629e-01, -8.90400335e-02, -6.05879799e-02,\n",
       "        4.68912989e-01, -1.67232737e-01,  1.34943217e-01,  2.14113906e-01,\n",
       "       -2.60165662e-01,  1.50442153e-01, -3.80127132e-02,  2.59744972e-01,\n",
       "       -2.29415610e-01, -6.18208647e-01, -1.59963727e-01, -4.31953728e-01,\n",
       "       -2.94960380e-01,  4.43524569e-01, -1.37890026e-01,  3.39863688e-01,\n",
       "       -4.57083620e-02,  3.19707207e-02, -3.17770690e-01,  6.15232885e-02,\n",
       "       -2.21318662e-01, -5.46769440e-01,  7.43940026e-02, -2.50698447e-01,\n",
       "       -1.92955136e-01, -8.32648873e-02,  6.07031286e-01, -9.69601214e-01,\n",
       "       -2.30979830e-01, -3.84056538e-01,  2.79464096e-01, -1.07552558e-01,\n",
       "        7.30241165e-02, -9.13565829e-02,  1.58481717e-01,  3.14642936e-01,\n",
       "        6.57802597e-02, -1.61519915e-01,  6.30533397e-02, -3.30130696e-01,\n",
       "       -8.95403922e-02,  1.42127797e-01, -3.16956520e-01, -6.30192935e-01,\n",
       "        4.85171139e-01, -6.17274284e-01,  7.55613983e-01, -1.28692463e-01,\n",
       "       -1.01099335e-01,  2.81251967e-01,  4.77329195e-02,  3.37882079e-02,\n",
       "       -8.03532079e-02, -2.73353636e-01,  1.26844093e-01, -1.01901226e-01,\n",
       "       -1.82253167e-01,  1.87504813e-02, -4.95303780e-01, -6.96807429e-02,\n",
       "        1.21057831e-01, -6.31959438e-01, -5.70664257e-02, -3.99302125e-01,\n",
       "        5.20306826e-01, -1.30332381e-01, -1.24967545e-01,  1.00299075e-01,\n",
       "       -9.32332695e-01,  2.17876863e-02,  4.80747551e-01,  1.59771085e-01,\n",
       "       -9.58937034e-02,  4.94970500e-01,  1.80012703e-01, -5.32362819e-01,\n",
       "        1.09825745e-01, -4.58546430e-01,  3.91475447e-02,  4.98840958e-01,\n",
       "       -7.96586871e-02,  3.74911636e-01,  6.97924316e-01,  1.96342692e-01,\n",
       "        6.78055704e-01,  7.55789801e-02,  1.63020015e-01, -2.58623421e-01,\n",
       "       -1.60862908e-01,  7.04513351e-03,  1.06580608e-01, -9.90405586e-03,\n",
       "        2.94420391e-01,  6.32461548e-01, -1.16727434e-01,  2.77682710e-02,\n",
       "        1.77517295e-01,  4.14125249e-02, -3.62961620e-01,  4.30706650e-01,\n",
       "        1.31393045e-01,  4.85919446e-01, -6.78747952e-01,  4.02605645e-02,\n",
       "       -7.31172860e-01,  2.14795768e-01,  7.83360422e-01,  3.29244018e-01,\n",
       "       -6.99650720e-02,  1.11952014e-01,  8.83074552e-02,  7.40610957e-02,\n",
       "       -2.45852247e-01,  4.11127776e-01,  1.37589186e-01, -3.34208339e-01,\n",
       "       -4.69711542e-01, -1.49226248e-01,  8.42884406e-02,  1.20327055e-01,\n",
       "        6.66770339e-02, -7.58494616e-01, -3.95074666e-01, -4.01359737e-01,\n",
       "        3.21104825e-01, -3.47220421e-01, -4.46776778e-01, -2.50656635e-01,\n",
       "       -3.22196573e-01, -5.36435992e-02, -5.55929780e-01, -2.82110237e-02,\n",
       "       -5.21513522e-01, -9.32269394e-01, -3.09135973e-01, -2.29903564e-01,\n",
       "        4.80770171e-01, -8.69662538e-02,  1.75359249e-01,  1.30201113e+00,\n",
       "        8.23138356e-02, -1.23569205e-01,  5.00842869e-01,  1.47707090e-01,\n",
       "        2.36700118e-01, -2.52940297e-01, -6.71044216e-02, -1.88365430e-02,\n",
       "        2.56734103e-01, -3.58441323e-01, -2.84148194e-02,  6.59537911e-01,\n",
       "        2.25745589e-01, -2.06396833e-01, -3.73154491e-01,  2.01089665e-01,\n",
       "       -6.76335990e-02, -1.46891475e-01,  1.80734277e-01,  1.44894244e-02,\n",
       "        4.48222399e-01,  1.27520924e-02,  3.37270536e-02, -1.75847694e-01,\n",
       "       -1.16400920e-01, -3.58473063e-01,  5.98399043e-01, -1.75403392e+00,\n",
       "        6.88041970e-02,  1.80653274e-01,  4.52878147e-01,  2.89505333e-01,\n",
       "       -2.16757655e-01,  1.67045504e-01, -3.32504332e-01, -3.60537231e-01,\n",
       "        1.38831705e-01,  4.06358004e-01,  1.96874261e-01,  3.00904930e-01,\n",
       "       -3.19775254e-01, -5.97965643e-02, -9.42768976e-02,  5.36490344e-02,\n",
       "       -3.42797697e-01, -2.57610291e-01, -1.29828617e-01, -1.12469777e-01,\n",
       "       -3.37558389e-01, -3.17534357e-01, -1.05004601e-01,  8.18596035e-02,\n",
       "       -5.43863595e-01, -3.23899925e-01,  5.67470074e-01, -6.44882083e-01,\n",
       "       -8.31691176e-02,  4.35380250e-01, -3.71240914e-01, -2.18951926e-02,\n",
       "        3.75932842e-01,  1.81925416e-01, -4.49294955e-01,  2.83872455e-01,\n",
       "        1.89091757e-01,  2.13866919e-01, -5.90090871e-01, -5.54028228e-02,\n",
       "       -2.90131450e-01, -1.00141264e-01,  1.23400493e-02,  7.02791154e-01,\n",
       "        2.93961465e-01, -3.42505611e-02, -3.86330485e-01, -1.82177246e-01,\n",
       "       -1.56918526e-01, -1.80699706e-01, -6.72974885e-02,  9.22428966e-02,\n",
       "        1.91492736e-01,  1.01153906e-02,  1.06992351e-03, -2.91246194e-02,\n",
       "        3.54266800e-02, -6.27771854e-01,  2.39883840e-01, -6.03365183e-01,\n",
       "       -4.10657525e-02,  3.30063283e-01,  3.64864528e-01,  1.66730821e-01,\n",
       "       -5.76718509e-01, -1.21990301e-01,  1.71580091e-01, -7.57430494e-02,\n",
       "        2.13251077e-02, -4.53002602e-02,  5.90881445e-02, -1.36509538e-01,\n",
       "       -2.02541858e-01,  1.03667974e+00,  9.41832829e-03, -9.93269160e-02,\n",
       "       -2.25916743e-01, -2.69489530e-02,  2.77405530e-02, -1.06507480e-01,\n",
       "       -1.61682516e-02,  3.10762227e-01,  6.07965849e-02,  1.62256613e-01,\n",
       "       -2.81514496e-01,  1.11455154e-02,  9.98737738e-02, -3.98895331e-02,\n",
       "        5.69281995e-01, -2.04071999e-01,  3.08405817e-01, -4.47958149e-02,\n",
       "       -5.14720380e-02,  5.33447623e-01, -3.59726697e-01, -3.61021519e-01,\n",
       "       -2.12406293e-01,  2.43081287e-01,  1.62987113e-02,  2.88764507e-01,\n",
       "       -2.41327167e-01, -1.86556220e-01,  2.19040409e-01, -2.98110068e-01,\n",
       "       -7.26294592e-02, -7.83576723e-03,  2.96072483e-01,  1.45287856e-01,\n",
       "       -2.07660213e-01, -2.39125162e-01,  1.99851125e-01,  1.46868736e-01,\n",
       "        4.32512052e-02,  7.07899779e-03,  2.20936071e-02, -3.87084752e-01,\n",
       "       -2.67065793e-01,  5.47213778e-02,  2.86183625e-01,  1.89897895e-01,\n",
       "        3.29011023e-01,  1.12482762e+00, -4.97313380e-01,  5.14402509e-01,\n",
       "       -1.98986866e-02,  5.06225407e-01, -8.56431797e-02, -1.39586136e-01,\n",
       "       -1.87338978e-01,  2.94506222e-01, -7.25955367e-02, -9.77693200e-02,\n",
       "       -7.04439759e-01, -1.16625018e-01,  6.50688171e-01,  2.25672841e-01,\n",
       "        6.04259968e-02,  9.39720497e-02,  2.42952287e-01, -3.31096470e-01,\n",
       "       -1.70659900e-01, -1.69500962e-01, -7.69041479e-03,  2.38894433e-01,\n",
       "        7.24347355e-03, -3.48209918e-01, -1.27401903e-01, -1.04182795e-01,\n",
       "        2.43794411e-01, -3.90853360e-02,  1.61306530e-01, -2.76143849e-01,\n",
       "       -6.10210955e-01, -9.63218361e-02,  1.31482184e-01,  3.29345942e-01,\n",
       "       -1.22302193e-02, -5.76319993e-02,  6.40140951e-01,  3.83785367e-02,\n",
       "        9.18063056e-03,  1.31909296e-01,  5.06344676e-01,  2.85177287e-02,\n",
       "        2.78855324e-01,  5.60869724e-02,  4.68519419e-01,  1.38097554e-02,\n",
       "       -7.78696388e-02,  5.18678427e-01, -3.53485286e-01,  8.33859667e-03,\n",
       "       -8.76776055e-02, -4.15365487e-01, -2.54395515e-01,  2.38907456e-01,\n",
       "       -4.89603817e-01,  7.23423004e-01, -2.46461868e-01, -3.10186863e-01,\n",
       "        6.85848057e-01, -1.33916736e-01, -7.00357854e-02,  5.03578842e-01,\n",
       "       -1.73593476e-01,  2.78424829e-01,  1.94484413e-01, -1.98190972e-01,\n",
       "       -2.06428207e-02,  1.61136594e-02, -1.23206936e-01,  1.85009390e-01,\n",
       "        1.34968638e-01, -3.67208160e-02, -9.84494612e-02,  7.90907443e-02,\n",
       "        3.99781913e-01, -6.60996512e-02,  2.33837143e-01, -8.65548104e-02,\n",
       "        2.93085545e-01,  1.87315643e-01,  3.42983305e-02,  3.77678834e-02,\n",
       "        4.18539524e-01,  2.58494526e-01, -2.48147398e-01, -2.95206070e-01,\n",
       "       -4.47994590e-01, -6.59316480e-02, -8.56001854e-01,  7.13604018e-02,\n",
       "       -1.61094204e-01,  4.47212964e-01,  6.32738546e-02,  2.75473803e-01,\n",
       "        5.52478433e-01,  2.63786167e-01,  1.80652912e-03, -2.42140457e-01,\n",
       "       -3.31318170e-01, -1.39987692e-01, -3.15948725e-01, -3.54745649e-02,\n",
       "       -1.33748487e-01, -3.20184112e-01,  6.52411044e-01, -5.98010659e-01,\n",
       "       -1.15851365e-01,  3.37301403e-01,  1.39068840e-02,  3.06654960e-01,\n",
       "       -3.57876211e-01,  1.75804690e-01, -7.62241557e-02, -2.89700806e-01,\n",
       "        3.76686484e-01,  2.41123542e-01,  4.33105886e-01, -3.25007617e-01,\n",
       "       -2.07676947e-01,  5.05473576e-02, -2.20499843e-01, -1.33988887e-01,\n",
       "        5.57767078e-02, -1.89921692e-01, -1.46284670e-01,  1.93095922e-01,\n",
       "        5.01820564e-01, -1.42598273e-02,  2.88017720e-01,  2.55266428e-01,\n",
       "       -2.44185701e-01,  2.31620103e-01,  5.11319637e-01, -5.06005138e-02,\n",
       "        1.10906795e-01, -1.98294893e-01,  1.86933607e-01, -3.88120532e-01,\n",
       "        3.68333727e-01,  1.48318410e-01,  2.93854505e-01, -2.49659002e-01,\n",
       "       -1.73024490e-01, -1.39366508e-01,  1.78418040e-01, -1.07881106e-01,\n",
       "       -8.20646212e-02,  4.38260466e-01, -1.63485229e-01,  1.67506650e-01,\n",
       "        2.18373403e-01, -1.67601794e-01, -2.76500434e-01, -8.25017542e-02,\n",
       "        4.28827554e-01, -3.87986898e-01,  4.47684228e-01,  5.15503064e-02,\n",
       "       -5.25254667e-01,  2.77463496e-01, -3.40018451e-01, -5.96875176e-02,\n",
       "        4.50960129e-01, -6.07209861e-01,  4.91425283e-02, -3.34070295e-01,\n",
       "       -2.42088988e-01,  1.54627591e-01,  1.48121223e-01,  9.62092280e-02,\n",
       "       -4.05066133e-01, -5.46146989e-01, -9.91383567e-02,  4.12882954e-01,\n",
       "       -1.51561588e-01, -7.51375854e-02, -1.71999902e-01, -5.15278019e-02,\n",
       "        3.37227434e-02, -4.87103850e-01, -2.49192685e-01, -4.58372176e-01,\n",
       "        2.28703409e-01,  6.01927936e-01,  1.43762067e-01, -7.61339590e-02,\n",
       "       -5.19478023e-02, -5.90813875e-01,  1.62430584e-01, -1.48231298e-01,\n",
       "        4.43966389e-01, -1.00897752e-01, -5.82342446e-01,  6.06778145e-01,\n",
       "       -1.77626252e-01,  1.88790306e-01,  2.91289926e-01,  2.50262380e-01,\n",
       "        5.20947397e-01, -5.71172684e-02, -3.96775678e-02,  1.47933453e-01,\n",
       "        1.01706944e-01,  8.11669305e-02,  2.40115449e-01, -2.64889538e-01,\n",
       "       -8.30494687e-02, -3.48304808e-01,  7.32839927e-02, -4.92543608e-01,\n",
       "       -9.17241499e-02,  1.68638498e-01,  3.95459563e-01,  1.32339671e-01,\n",
       "        1.12837508e-01,  3.92917693e-01,  6.88775003e-01,  2.46401715e+00,\n",
       "        3.02489549e-01,  4.46244657e-01, -1.01269439e-01, -1.06576249e-01,\n",
       "       -2.02787042e-01, -1.08125061e-01,  2.57664621e-01, -2.60689825e-01,\n",
       "        2.83961207e-01,  6.21410310e-02,  2.03753695e-01,  2.41614476e-01,\n",
       "       -1.09027967e-01, -3.83879632e-01,  8.59245360e-02, -3.04567784e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word_embeddings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d7a4a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 07:29:42.585951: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-22 07:29:42.673891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-22 07:29:42.673977: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c348075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_array = data['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c3ce4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39c6c82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8c13ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a18be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = data['word_embeddings'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcd999bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f632fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34159, 768)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46eec72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34159, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8bb63a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34159, 768)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c9474417",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_Y, test_Y = train_test_split(x,dummy_y, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01a7bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=768, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(25,activation=\"relu\"))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "# estimator = KerasClassifier(build_fn=baseline_model, epochs=2, batch_size=5, verbose=1)\n",
    "# kfold = KFold(n_splits=2, shuffle=True)\n",
    "# results = cross_val_score(estimator, x,dummy_y, cv=kfold)\n",
    "# print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2ee4eb16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2733/2733 [==============================] - 10s 3ms/step - loss: 0.7325 - accuracy: 0.6860\n",
      "Epoch 2/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.6749 - accuracy: 0.7134\n",
      "Epoch 3/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.6521 - accuracy: 0.7229\n",
      "Epoch 4/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.6290 - accuracy: 0.7330\n",
      "Epoch 5/20\n",
      "2733/2733 [==============================] - 10s 4ms/step - loss: 0.6070 - accuracy: 0.7440\n",
      "Epoch 6/20\n",
      "2733/2733 [==============================] - 10s 4ms/step - loss: 0.5875 - accuracy: 0.7519\n",
      "Epoch 7/20\n",
      "2733/2733 [==============================] - 10s 4ms/step - loss: 0.5674 - accuracy: 0.7612\n",
      "Epoch 8/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.5505 - accuracy: 0.7690\n",
      "Epoch 9/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.5346 - accuracy: 0.7752\n",
      "Epoch 10/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.5121 - accuracy: 0.7873\n",
      "Epoch 11/20\n",
      "2733/2733 [==============================] - 10s 4ms/step - loss: 0.4941 - accuracy: 0.7940\n",
      "Epoch 12/20\n",
      "2733/2733 [==============================] - 10s 4ms/step - loss: 0.4772 - accuracy: 0.8014\n",
      "Epoch 13/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.4582 - accuracy: 0.8092\n",
      "Epoch 14/20\n",
      "2733/2733 [==============================] - 9s 3ms/step - loss: 0.4430 - accuracy: 0.8181\n",
      "Epoch 15/20\n",
      "2733/2733 [==============================] - 8s 3ms/step - loss: 0.4248 - accuracy: 0.8264\n",
      "Epoch 16/20\n",
      "2733/2733 [==============================] - 8s 3ms/step - loss: 0.4127 - accuracy: 0.8256\n",
      "Epoch 17/20\n",
      "2733/2733 [==============================] - 8s 3ms/step - loss: 0.3927 - accuracy: 0.8368\n",
      "Epoch 18/20\n",
      "2733/2733 [==============================] - 8s 3ms/step - loss: 0.3820 - accuracy: 0.8424\n",
      "Epoch 19/20\n",
      "2733/2733 [==============================] - 10s 4ms/step - loss: 0.3671 - accuracy: 0.8489\n",
      "Epoch 20/20\n",
      "2733/2733 [==============================] - 11s 4ms/step - loss: 0.3560 - accuracy: 0.8558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3b61b6d90>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit( train_x,train_Y, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c788cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4c137d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 0.8656 - accuracy: 0.7168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8656483888626099, 0.7167739868164062]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8cf87d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cd217a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "58fe0fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d3b3a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_y = np.argmax(test_Y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "72e5c822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2129  152  445]\n",
      " [ 243  521  313]\n",
      " [ 516  266 2247]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(encoded_test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e1a32cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      2726\n",
      "           1       0.55      0.48      0.52      1077\n",
      "           2       0.75      0.74      0.74      3029\n",
      "\n",
      "    accuracy                           0.72      6832\n",
      "   macro avg       0.68      0.67      0.67      6832\n",
      "weighted avg       0.71      0.72      0.71      6832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(encoded_test_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d4a8d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5566671408418981"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = train_X.to_list()\n",
    "y = train_y\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,\n",
    "    random_state=0)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a683b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6459912598347778"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53e40902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6438628545767323"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "    min_samples_split=2, random_state=0)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a03c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11e4a203",
   "metadata": {},
   "source": [
    "## Finetuning with NepBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "706da9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Shushant/nepaliBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Shushant/nepaliBERT and are newly initialized: ['classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Shushant/nepaliBERT\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab57932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 22:53:52.854163: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-17 22:53:52.878462: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-17 22:53:52.878476: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6ce2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ad2080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Shushant--CovidNepaliTweets-00a71fabf99a7743\n",
      "Reusing dataset csv (/home/fm-pc-lt-228/.cache/huggingface/datasets/Shushant___csv/Shushant--CovidNepaliTweets-00a71fabf99a7743/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015757083892822266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 59,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9180d10665424da4278d5bd7ee7601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Label': 0,\n",
       " 'Text': 'नेपाली कांग्रेसका वरिष्ठनेता अादरणिय श्री रामचन्द्र पौडेलज्यूको प्रमुख अातिथ्यतामा कोभिड पछिको विश्वसन्दर्भमा लोकतान्त्रिक समाजबादको सान्दर्भिकता विषयक प्रदेश स्तरिय जुम मिटिङ्ग फेसबुकमा गते जेष्ठ बुधबार बजे लाईभ गरिनेछ सामाजिक लोकतन्त्र अध्ययन केन्द्र'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Shushant/CovidNepaliTweets\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7904c32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/Shushant/nepaliBERT/resolve/main/config.json from cache at /home/fm-pc-lt-228/.cache/huggingface/transformers/c642996ea6b3b6351e3519c0b5059b07a6b8a1a8e4961bf81d181326b75cabfe.3abddfe906646a59813d34e11ed576b8ddb2023553640fa3ce71f000d3c234d0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Shushant/nepaliBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/Shushant/nepaliBERT/resolve/main/vocab.txt from cache at /home/fm-pc-lt-228/.cache/huggingface/transformers/22c9a4d244e3f42334b0f06c2faa3df5130e6b533c42be86c1e3ed28ba385eb4.a31f6709bd9b70ccff6b17176e4c942c6860ae0b36de53bafc7ab6a74ab3e735\n",
      "loading file https://huggingface.co/Shushant/nepaliBERT/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/Shushant/nepaliBERT/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/Shushant/nepaliBERT/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/Shushant/nepaliBERT/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/Shushant/nepaliBERT/resolve/main/config.json from cache at /home/fm-pc-lt-228/.cache/huggingface/transformers/c642996ea6b3b6351e3519c0b5059b07a6b8a1a8e4961bf81d181326b75cabfe.3abddfe906646a59813d34e11ed576b8ddb2023553640fa3ce71f000d3c234d0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Shushant/nepaliBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/Shushant/nepaliBERT/resolve/main/config.json from cache at /home/fm-pc-lt-228/.cache/huggingface/transformers/c642996ea6b3b6351e3519c0b5059b07a6b8a1a8e4961bf81d181326b75cabfe.3abddfe906646a59813d34e11ed576b8ddb2023553640fa3ce71f000d3c234d0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"Shushant/nepaliBERT\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00965118408203125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 59,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 27,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f418a73fd3e74470b3af3f4f4434929f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009561538696289062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 59,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 7,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d74ea07c7249be96d3b2879252f14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Shushant/nepaliBERT\")\n",
    "\n",
    "max_length = 61\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Text'], padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7590bae7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Label': 1,\n",
       " 'Text': 'आचार्य जी हर बिमारी का इलाज ढुढलेते हैं आप अब तक कोभीड का कोइ इलाज वा दवा क्यों नहिं खोज पाए हैं',\n",
       " 'input_ids': [2,\n",
       "  8575,\n",
       "  1022,\n",
       "  2260,\n",
       "  2699,\n",
       "  7590,\n",
       "  1714,\n",
       "  1701,\n",
       "  9525,\n",
       "  1037,\n",
       "  380,\n",
       "  1061,\n",
       "  4102,\n",
       "  402,\n",
       "  4167,\n",
       "  2227,\n",
       "  30176,\n",
       "  1805,\n",
       "  4690,\n",
       "  1051,\n",
       "  1701,\n",
       "  3615,\n",
       "  9525,\n",
       "  1037,\n",
       "  1862,\n",
       "  8773,\n",
       "  367,\n",
       "  1700,\n",
       "  11992,\n",
       "  1027,\n",
       "  2426,\n",
       "  4583,\n",
       "  402,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d20dd332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets['train'][0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b960bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb0d3d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50154ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "496ce1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: Label, Text.\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 375\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_121287/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m                 if (\n",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m         )\n\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;31m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;31m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extended_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;31m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nepali/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mget_extended_attention_mask\u001b[0;34m(self, attention_mask, input_shape, device)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Since we are adding it to the raw scores before the softmax, this is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# effectively the same as removing these entirely.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mextended_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fp16 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mextended_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734302a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
