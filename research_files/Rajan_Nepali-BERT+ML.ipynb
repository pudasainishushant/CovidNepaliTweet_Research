{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04b54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/home/fm-pc-lt-228/Desktop/covid_nepali_tweets/covid19_tweeter_dataset (copy).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fb284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoTokenizer, AutoModelForMaskedLM\n",
    "from scipy.spatial.distance import cosine \n",
    "import tokenizers \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import snowballstemmer\n",
    "import numpy\n",
    "import os \n",
    "import re\n",
    "import json\n",
    "import pickle \n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"Rajan/NepaliBERT\", output_hidden_states = True, return_dict = True, output_attentions = True)\n",
    "\n",
    "tokenizers = AutoTokenizer.from_pretrained(\"Rajan/NepaliBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68208dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding_sentence(input_sentence):\n",
    "    md = model\n",
    "    tokenizer = tokenizers\n",
    "#     md = local_model\n",
    "#     tokenizer = local_tokenizers\n",
    "    marked_text = \" [CLS] \" + input_sentence + \" [SEP] \"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(indexed_tokens) \n",
    "    \n",
    "    # Convert inputs to Pytorch tensors\n",
    "    tokens_tensors = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = md(tokens_tensors, segments_tensors)\n",
    "        # removing the first hidden state\n",
    "        # the first state is the input state \n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "#         print(hidden_states[-2])\n",
    "        # second_hidden_states = outputs[2]\n",
    "    # hidden_states has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "    # token_vecs is a tensor with shape [22 x 768]\n",
    "#     token_vecs = hidden_states[-2][0]\n",
    "    # get last four layers\n",
    "#     last_four_layers = [hidden_states[i] for i in (-1,-2, -3,-4)]\n",
    "    # cast layers to a tuple and concatenate over the last dimension\n",
    "#     cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "#     print(cat_hidden_states.shape)\n",
    "#     import pdb;pdb.set_trace()\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    # take the mean of the concatenated vector over the token dimension\n",
    "#     sentence_embedding = torch.mean(cat_hidden_states, dim=0).squeeze()\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "#     sentence_embedding = torch.mean(token_vecs, dim=1)\n",
    "    return sentence_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bc139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_embeddings'] = data['Tweet'].apply(get_bert_embedding_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf6b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"embeddings_data_nepali_BERT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16889493",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data['word_embeddings'], data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fad91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f706ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba420c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(train_X.tolist(), train_y)\n",
    "#svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4c4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(test_X.tolist())\n",
    "# svc_pred = svc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9e1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2000   44  777]\n",
      " [ 298  426  575]\n",
      " [ 466   40 2454]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614ae1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.71      0.72      2821\n",
      "           0       0.84      0.33      0.47      1299\n",
      "           1       0.64      0.83      0.73      2960\n",
      "\n",
      "    accuracy                           0.69      7080\n",
      "   macro avg       0.73      0.62      0.64      7080\n",
      "weighted avg       0.71      0.69      0.68      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4359624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6892655367231638"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, svc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10411de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "random_forest.fit(train_X.tolist(), train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2098b7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892655367231638\n",
      "[[1418    0 1403]\n",
      " [ 286    9 1004]\n",
      " [ 398    0 2562]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.50      0.58      2821\n",
      "           0       1.00      0.01      0.01      1299\n",
      "           1       0.52      0.87      0.65      2960\n",
      "\n",
      "    accuracy                           0.56      7080\n",
      "   macro avg       0.73      0.46      0.41      7080\n",
      "weighted avg       0.67      0.56      0.50      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_pred = random_forest.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, svc_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, random_pred))\n",
    "\n",
    "print(classification_report(test_y, random_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03baf8",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "054ccf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b65e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5553672316384181\n",
      "[[1355  471  995]\n",
      " [ 192  587  520]\n",
      " [ 364  606 1990]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.48      0.57      2821\n",
      "           0       0.35      0.45      0.40      1299\n",
      "           1       0.57      0.67      0.62      2960\n",
      "\n",
      "    accuracy                           0.56      7080\n",
      "   macro avg       0.54      0.53      0.53      7080\n",
      "weighted avg       0.58      0.56      0.56      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_pred = gnb.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, gnb_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, gnb_pred))\n",
    "\n",
    "print(classification_report(test_y, gnb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac97588",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3edaf086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_boost_clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada_boost_clf.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65a7c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6211864406779661\n",
      "[[1812  146  863]\n",
      " [ 358  420  521]\n",
      " [ 623  171 2166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.64      0.65      2821\n",
      "           0       0.57      0.32      0.41      1299\n",
      "           1       0.61      0.73      0.67      2960\n",
      "\n",
      "    accuracy                           0.62      7080\n",
      "   macro avg       0.61      0.57      0.57      7080\n",
      "weighted avg       0.62      0.62      0.61      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_pred = ada_boost_clf.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, adaboost_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, adaboost_pred))\n",
    "\n",
    "print(classification_report(test_y, adaboost_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079f42a",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b41cabf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "decision_tree.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0982c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5214689265536723\n",
      "[[2021    0  800]\n",
      " [ 792    0  507]\n",
      " [1289    0 1671]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.49      0.72      0.58      2821\n",
      "           0       0.00      0.00      0.00      1299\n",
      "           1       0.56      0.56      0.56      2960\n",
      "\n",
      "    accuracy                           0.52      7080\n",
      "   macro avg       0.35      0.43      0.38      7080\n",
      "weighted avg       0.43      0.52      0.47      7080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "decision_pred = decision_tree.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, decision_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, decision_pred))\n",
    "\n",
    "print(classification_report(test_y, decision_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211f781",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d96f96d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc_clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "etc_clf.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07c68475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6529661016949152\n",
      "[[1796   40  985]\n",
      " [ 302  374  623]\n",
      " [ 462   45 2453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.64      0.67      2821\n",
      "           0       0.81      0.29      0.43      1299\n",
      "           1       0.60      0.83      0.70      2960\n",
      "\n",
      "    accuracy                           0.65      7080\n",
      "   macro avg       0.71      0.58      0.60      7080\n",
      "weighted avg       0.68      0.65      0.64      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etc_pred = etc_clf.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, etc_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, etc_pred))\n",
    "\n",
    "print(classification_report(test_y, etc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ed623",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f628006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d2855ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785310734463277\n",
      "[[1998  106  717]\n",
      " [ 309  504  486]\n",
      " [ 527  131 2302]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.71      0.71      2821\n",
      "           0       0.68      0.39      0.49      1299\n",
      "           1       0.66      0.78      0.71      2960\n",
      "\n",
      "    accuracy                           0.68      7080\n",
      "   macro avg       0.68      0.62      0.64      7080\n",
      "weighted avg       0.68      0.68      0.67      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred = logreg.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, lr_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, lr_pred))\n",
    "\n",
    "print(classification_report(test_y, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c2482",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c974c0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5053dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6446327683615819\n",
      "[[2047  147  627]\n",
      " [ 421  460  418]\n",
      " [ 745  158 2057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.73      0.68      2821\n",
      "           0       0.60      0.35      0.45      1299\n",
      "           1       0.66      0.69      0.68      2960\n",
      "\n",
      "    accuracy                           0.64      7080\n",
      "   macro avg       0.63      0.59      0.60      7080\n",
      "weighted avg       0.64      0.64      0.64      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh_pred = neigh.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, neigh_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, neigh_pred))\n",
    "\n",
    "print(classification_report(test_y, neigh_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1c5ed",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6622559d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=300, random_state=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=1, max_iter=300)\n",
    "mlp.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8581fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6601694915254237\n",
      "[[1939  269  613]\n",
      " [ 258  659  382]\n",
      " [ 576  308 2076]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.69      0.69      2821\n",
      "           0       0.53      0.51      0.52      1299\n",
      "           1       0.68      0.70      0.69      2960\n",
      "\n",
      "    accuracy                           0.66      7080\n",
      "   macro avg       0.64      0.63      0.63      7080\n",
      "weighted avg       0.66      0.66      0.66      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_pred = mlp.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, mlp_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, mlp_pred))\n",
    "\n",
    "print(classification_report(test_y, mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198d69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d74255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797102cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
