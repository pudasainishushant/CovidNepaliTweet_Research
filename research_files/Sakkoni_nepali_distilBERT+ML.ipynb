{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04b54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/home/fm-pc-lt-228/Desktop/covid_nepali_tweets/covid19_tweeter_dataset (copy).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fb284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoTokenizer, AutoModelForMaskedLM\n",
    "from scipy.spatial.distance import cosine \n",
    "import tokenizers \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import snowballstemmer\n",
    "import numpy\n",
    "import os \n",
    "import re\n",
    "import json\n",
    "import pickle \n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"Sakonii/deberta-base-nepali\", output_hidden_states = True, return_dict = True, output_attentions = True)\n",
    "\n",
    "tokenizers = AutoTokenizer.from_pretrained(\"Sakonii/deberta-base-nepali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68208dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding_sentence(input_sentence):\n",
    "    md = model\n",
    "    tokenizer = tokenizers\n",
    "#     md = local_model\n",
    "#     tokenizer = local_tokenizers\n",
    "    marked_text = \" [CLS] \" + input_sentence + \" [SEP] \"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(indexed_tokens) \n",
    "    \n",
    "    # Convert inputs to Pytorch tensors\n",
    "    tokens_tensors = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = md(tokens_tensors, segments_tensors)\n",
    "        # removing the first hidden state\n",
    "        # the first state is the input state \n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "#         print(hidden_states[-2])\n",
    "        # second_hidden_states = outputs[2]\n",
    "    # hidden_states has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "    # token_vecs is a tensor with shape [22 x 768]\n",
    "#     token_vecs = hidden_states[-2][0]\n",
    "    # get last four layers\n",
    "#     last_four_layers = [hidden_states[i] for i in (-1,-2, -3,-4)]\n",
    "    # cast layers to a tuple and concatenate over the last dimension\n",
    "#     cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "#     print(cat_hidden_states.shape)\n",
    "#     import pdb;pdb.set_trace()\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    # take the mean of the concatenated vector over the token dimension\n",
    "#     sentence_embedding = torch.mean(cat_hidden_states, dim=0).squeeze()\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "#     sentence_embedding = torch.mean(token_vecs, dim=1)\n",
    "    return sentence_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bc139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_embeddings'] = data['Tweet'].apply(get_bert_embedding_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf6b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"embeddings_data_nepali_BERT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16889493",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data['word_embeddings'], data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fad91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f706ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba420c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(train_X.tolist(), train_y)\n",
    "#svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4c4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(test_X.tolist())\n",
    "# svc_pred = svc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9e1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2214   44  563]\n",
      " [ 336  428  535]\n",
      " [ 575   37 2348]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614ae1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.78      0.74      2821\n",
      "           0       0.84      0.33      0.47      1299\n",
      "           1       0.68      0.79      0.73      2960\n",
      "\n",
      "    accuracy                           0.70      7080\n",
      "   macro avg       0.74      0.64      0.65      7080\n",
      "weighted avg       0.72      0.70      0.69      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4359624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7048022598870056"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, svc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6259df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "random_forest.fit(train_X.tolist(), train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bba792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5759887005649718\n",
      "[[1390    0 1431]\n",
      " [ 214   32 1053]\n",
      " [ 304    0 2656]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.49      0.59      2821\n",
      "           0       1.00      0.02      0.05      1299\n",
      "           1       0.52      0.90      0.66      2960\n",
      "\n",
      "    accuracy                           0.58      7080\n",
      "   macro avg       0.75      0.47      0.43      7080\n",
      "weighted avg       0.69      0.58      0.52      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_pred = random_forest.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, random_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, random_pred))\n",
    "\n",
    "print(classification_report(test_y, random_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7801a",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe0acc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b4efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5983050847457627\n",
      "[[1799  438  584]\n",
      " [ 302  597  400]\n",
      " [ 620  500 1840]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.64      0.65      2821\n",
      "           0       0.39      0.46      0.42      1299\n",
      "           1       0.65      0.62      0.64      2960\n",
      "\n",
      "    accuracy                           0.60      7080\n",
      "   macro avg       0.57      0.57      0.57      7080\n",
      "weighted avg       0.61      0.60      0.60      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_pred = gnb.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, gnb_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, gnb_pred))\n",
    "\n",
    "print(classification_report(test_y, gnb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbfd1dd",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e1f010a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_boost_clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada_boost_clf.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "813a2af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6367231638418079\n",
      "[[1964  155  702]\n",
      " [ 367  443  489]\n",
      " [ 673  186 2101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.70      0.67      2821\n",
      "           0       0.57      0.34      0.43      1299\n",
      "           1       0.64      0.71      0.67      2960\n",
      "\n",
      "    accuracy                           0.64      7080\n",
      "   macro avg       0.62      0.58      0.59      7080\n",
      "weighted avg       0.63      0.64      0.63      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_pred = ada_boost_clf.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, adaboost_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, adaboost_pred))\n",
    "\n",
    "print(classification_report(test_y, adaboost_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201fad9",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a6cddb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "decision_tree.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5be5a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5362994350282486\n",
      "[[1757   44 1020]\n",
      " [ 532  151  616]\n",
      " [1018   53 1889]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.62      0.57      2821\n",
      "           0       0.61      0.12      0.20      1299\n",
      "           1       0.54      0.64      0.58      2960\n",
      "\n",
      "    accuracy                           0.54      7080\n",
      "   macro avg       0.56      0.46      0.45      7080\n",
      "weighted avg       0.55      0.54      0.51      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_pred = decision_tree.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, decision_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, decision_pred))\n",
    "\n",
    "print(classification_report(test_y, decision_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbbfa29",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a223b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc_clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "etc_clf.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc06c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6692090395480226\n",
      "[[1930   75  816]\n",
      " [ 282  395  622]\n",
      " [ 495   52 2413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.68      0.70      2821\n",
      "           0       0.76      0.30      0.43      1299\n",
      "           1       0.63      0.82      0.71      2960\n",
      "\n",
      "    accuracy                           0.67      7080\n",
      "   macro avg       0.70      0.60      0.61      7080\n",
      "weighted avg       0.68      0.67      0.65      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etc_pred = etc_clf.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, etc_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, etc_pred))\n",
    "\n",
    "print(classification_report(test_y, etc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683440e2",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e678700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8503eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6990112994350283\n",
      "[[2130  135  556]\n",
      " [ 308  528  463]\n",
      " [ 526  143 2291]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.76      0.74      2821\n",
      "           0       0.66      0.41      0.50      1299\n",
      "           1       0.69      0.77      0.73      2960\n",
      "\n",
      "    accuracy                           0.70      7080\n",
      "   macro avg       0.69      0.65      0.66      7080\n",
      "weighted avg       0.70      0.70      0.69      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred = logreg.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, lr_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, lr_pred))\n",
    "\n",
    "print(classification_report(test_y, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f99220",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57d1c5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5ea6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6413841807909605\n",
      "[[2146  153  522]\n",
      " [ 454  454  391]\n",
      " [ 868  151 1941]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.76      0.68      2821\n",
      "           0       0.60      0.35      0.44      1299\n",
      "           1       0.68      0.66      0.67      2960\n",
      "\n",
      "    accuracy                           0.64      7080\n",
      "   macro avg       0.63      0.59      0.60      7080\n",
      "weighted avg       0.64      0.64      0.63      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh_pred = neigh.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, neigh_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, neigh_pred))\n",
    "\n",
    "print(classification_report(test_y, neigh_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0287f",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5baaef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=300, random_state=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=1, max_iter=300)\n",
    "mlp.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20c090c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6768361581920904\n",
      "[[2012  218  591]\n",
      " [ 274  648  377]\n",
      " [ 536  292 2132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.71      0.71      2821\n",
      "           0       0.56      0.50      0.53      1299\n",
      "           1       0.69      0.72      0.70      2960\n",
      "\n",
      "    accuracy                           0.68      7080\n",
      "   macro avg       0.65      0.64      0.65      7080\n",
      "weighted avg       0.67      0.68      0.68      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_pred = mlp.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, mlp_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, mlp_pred))\n",
    "\n",
    "print(classification_report(test_y, mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde825c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c8cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
