{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f04b54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/home/fm-pc-lt-228/Desktop/covid_nepali_tweets/covid19_tweeter_dataset (copy).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fb284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoTokenizer, AutoModelForMaskedLM\n",
    "from scipy.spatial.distance import cosine \n",
    "import tokenizers \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import snowballstemmer\n",
    "import numpy\n",
    "import os \n",
    "import re\n",
    "import json\n",
    "import pickle \n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"Shushant/nepaliBERT\", output_hidden_states = True, return_dict = True, output_attentions = True)\n",
    "\n",
    "tokenizers = AutoTokenizer.from_pretrained(\"Shushant/nepaliBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68208dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding_sentence(input_sentence):\n",
    "    md = model\n",
    "    tokenizer = tokenizers\n",
    "#     md = local_model\n",
    "#     tokenizer = local_tokenizers\n",
    "    marked_text = \" [CLS] \" + input_sentence + \" [SEP] \"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(indexed_tokens) \n",
    "    \n",
    "    # Convert inputs to Pytorch tensors\n",
    "    tokens_tensors = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = md(tokens_tensors, segments_tensors)\n",
    "        # removing the first hidden state\n",
    "        # the first state is the input state \n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "#         print(hidden_states[-2])\n",
    "        # second_hidden_states = outputs[2]\n",
    "    # hidden_states has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "    # token_vecs is a tensor with shape [22 x 768]\n",
    "#     token_vecs = hidden_states[-2][0]\n",
    "    # get last four layers\n",
    "#     last_four_layers = [hidden_states[i] for i in (-1,-2, -3,-4)]\n",
    "    # cast layers to a tuple and concatenate over the last dimension\n",
    "#     cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "#     print(cat_hidden_states.shape)\n",
    "#     import pdb;pdb.set_trace()\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    # take the mean of the concatenated vector over the token dimension\n",
    "#     sentence_embedding = torch.mean(cat_hidden_states, dim=0).squeeze()\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "#     sentence_embedding = torch.mean(token_vecs, dim=1)\n",
    "    return sentence_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0bc139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_embeddings'] = data['Tweet'].apply(get_bert_embedding_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf6b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"embeddings_data_nepali_BERT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16889493",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data['word_embeddings'], data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fad91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f706ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba420c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(train_X.tolist(), train_y)\n",
    "#svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4c4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(test_X.tolist())\n",
    "# svc_pred = svc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf9e1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2286   65  470]\n",
      " [ 286  534  479]\n",
      " [ 506   68 2386]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614ae1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.81      0.78      2821\n",
      "           0       0.80      0.41      0.54      1299\n",
      "           1       0.72      0.81      0.76      2960\n",
      "\n",
      "    accuracy                           0.74      7080\n",
      "   macro avg       0.75      0.68      0.69      7080\n",
      "weighted avg       0.74      0.74      0.73      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4359624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353107344632769"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, svc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2799ed75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "random_forest.fit(train_X.tolist(), train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5cbc9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5796610169491525\n",
      "[[1377    0 1444]\n",
      " [ 135   20 1144]\n",
      " [ 253    0 2707]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.49      0.60      2821\n",
      "           0       1.00      0.02      0.03      1299\n",
      "           1       0.51      0.91      0.66      2960\n",
      "\n",
      "    accuracy                           0.58      7080\n",
      "   macro avg       0.76      0.47      0.43      7080\n",
      "weighted avg       0.71      0.58      0.52      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_pred = random_forest.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, random_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, random_pred))\n",
    "\n",
    "print(classification_report(test_y, random_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "961ba877",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_174761/3117902350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n\u001b[1;32m      3\u001b[0m     max_depth=1, random_state=0).fit(train_X.tolist(), train_y)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "    max_depth=1, random_state=0).fit(train_X.tolist(), train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4791a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6929378531073447\n",
      "[[2087  145  589]\n",
      " [ 296  555  448]\n",
      " [ 535  161 2264]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.74      0.73      2821\n",
      "           0       0.64      0.43      0.51      1299\n",
      "           1       0.69      0.76      0.72      2960\n",
      "\n",
      "    accuracy                           0.69      7080\n",
      "   macro avg       0.68      0.64      0.65      7080\n",
      "weighted avg       0.69      0.69      0.69      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbc_pred = gb_clf.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, gbc_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, gbc_pred))\n",
    "\n",
    "print(classification_report(test_y, gbc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0019fb73",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d870e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd7e8317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6152542372881356\n",
      "[[1618  462  741]\n",
      " [ 209  668  422]\n",
      " [ 451  439 2070]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.57      0.63      2821\n",
      "           0       0.43      0.51      0.47      1299\n",
      "           1       0.64      0.70      0.67      2960\n",
      "\n",
      "    accuracy                           0.62      7080\n",
      "   macro avg       0.59      0.60      0.59      7080\n",
      "weighted avg       0.63      0.62      0.62      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_pred = gnb.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, gnb_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, gnb_pred))\n",
    "\n",
    "print(classification_report(test_y, gnb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac2c96",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "873aee1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_boost_clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "ada_boost_clf.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8585cc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6676553672316384\n",
      "[[2033  155  633]\n",
      " [ 304  528  467]\n",
      " [ 610  184 2166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.72      0.70      2821\n",
      "           0       0.61      0.41      0.49      1299\n",
      "           1       0.66      0.73      0.70      2960\n",
      "\n",
      "    accuracy                           0.67      7080\n",
      "   macro avg       0.65      0.62      0.63      7080\n",
      "weighted avg       0.66      0.67      0.66      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_pred = ada_boost_clf.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, adaboost_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, adaboost_pred))\n",
    "\n",
    "print(classification_report(test_y, adaboost_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de21e35",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17c4a206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "decision_tree.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c568b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5269774011299435\n",
      "[[ 957    0 1864]\n",
      " [  81    0 1218]\n",
      " [ 186    0 2774]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.34      0.47      2821\n",
      "           0       0.00      0.00      0.00      1299\n",
      "           1       0.47      0.94      0.63      2960\n",
      "\n",
      "    accuracy                           0.53      7080\n",
      "   macro avg       0.42      0.43      0.37      7080\n",
      "weighted avg       0.51      0.53      0.45      7080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "decision_pred = decision_tree.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, decision_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, decision_pred))\n",
    "\n",
    "print(classification_report(test_y, decision_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9435f6",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2744b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc_clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "etc_clf.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ab575c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.701271186440678\n",
      "[[1990   47  784]\n",
      " [ 250  472  577]\n",
      " [ 412   45 2503]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.71      0.73      2821\n",
      "           0       0.84      0.36      0.51      1299\n",
      "           1       0.65      0.85      0.73      2960\n",
      "\n",
      "    accuracy                           0.70      7080\n",
      "   macro avg       0.75      0.64      0.66      7080\n",
      "weighted avg       0.72      0.70      0.69      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etc_pred = etc_clf.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, etc_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, etc_pred))\n",
    "\n",
    "print(classification_report(test_y, etc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d98447",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02d8ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6de38e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7182203389830508\n",
      "[[2154  151  516]\n",
      " [ 272  612  415]\n",
      " [ 468  173 2319]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.76      0.75      2821\n",
      "           0       0.65      0.47      0.55      1299\n",
      "           1       0.71      0.78      0.75      2960\n",
      "\n",
      "    accuracy                           0.72      7080\n",
      "   macro avg       0.70      0.67      0.68      7080\n",
      "weighted avg       0.71      0.72      0.71      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred = logreg.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, lr_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, lr_pred))\n",
    "\n",
    "print(classification_report(test_y, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808efce9",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1162739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "add46b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6841807909604519\n",
      "[[2132  129  560]\n",
      " [ 397  537  365]\n",
      " [ 640  145 2175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.76      0.71      2821\n",
      "           0       0.66      0.41      0.51      1299\n",
      "           1       0.70      0.73      0.72      2960\n",
      "\n",
      "    accuracy                           0.68      7080\n",
      "   macro avg       0.68      0.63      0.65      7080\n",
      "weighted avg       0.68      0.68      0.68      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neigh_pred = neigh.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, neigh_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, neigh_pred))\n",
    "\n",
    "print(classification_report(test_y, neigh_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc46af6",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c8f6068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=300, random_state=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=1, max_iter=300)\n",
    "mlp.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59f7c0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046610169491525\n",
      "[[2086  210  525]\n",
      " [ 254  705  340]\n",
      " [ 527  235 2198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.74      0.73      2821\n",
      "           0       0.61      0.54      0.58      1299\n",
      "           1       0.72      0.74      0.73      2960\n",
      "\n",
      "    accuracy                           0.70      7080\n",
      "   macro avg       0.69      0.67      0.68      7080\n",
      "weighted avg       0.70      0.70      0.70      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_pred = mlp.predict(test_X.tolist())\n",
    "print(accuracy_score(test_y, mlp_pred))\n",
    "\n",
    "print(confusion_matrix(test_y, mlp_pred))\n",
    "\n",
    "print(classification_report(test_y, mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beccfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caea076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574daa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ddede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282ea94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2d11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3ebac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
