{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "656fa477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67c953dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/fm-pc-lt-228/Desktop/covid_nepali_tweets/covid19_tweeter_dataset (copy).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3801e31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35400, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fef12233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    14998\n",
       "-1    13606\n",
       " 0     6796\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "007720ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoTokenizer, AutoModelForMaskedLM\n",
    "from scipy.spatial.distance import cosine \n",
    "import tokenizers \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import snowballstemmer\n",
    "import numpy\n",
    "import os \n",
    "import re\n",
    "import json\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b519b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"Shushant/nepaliBERT\", output_hidden_states = True, return_dict = True, output_attentions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7dc414c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = AutoTokenizer.from_pretrained(\"Shushant/nepaliBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e1a612",
   "metadata": {},
   "source": [
    "pickle.dump(model, open('bert_embeddings','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9b5da",
   "metadata": {},
   "source": [
    "pickle.dump(tokenizers, open('bert_tokenizers','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e3242f",
   "metadata": {},
   "source": [
    "model = pickle.load(open('bert_embeddings','rb'))\n",
    "tokenizers= pickle.load(open('bert_tokenizers','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1871cd20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['क',\n",
       " 'मौ',\n",
       " '##ज',\n",
       " '##दा',\n",
       " 'लोक',\n",
       " '##तान',\n",
       " '##तर',\n",
       " '##िक',\n",
       " 'वय',\n",
       " '##वस',\n",
       " '##था',\n",
       " 'राज',\n",
       " '##य',\n",
       " 'पन',\n",
       " '##ः',\n",
       " '##सर',\n",
       " '##चना',\n",
       " '##सग',\n",
       " 'जोडिएका',\n",
       " 'हिजोका',\n",
       " 'सवाल',\n",
       " '##हर',\n",
       " '##लाई',\n",
       " 'यथा',\n",
       " '##स',\n",
       " '##थिति',\n",
       " '##मा',\n",
       " 'छोड',\n",
       " '##र',\n",
       " 'सबल',\n",
       " 'होला',\n",
       " '?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers.tokenize(\"के मौजुदा लोकतान्त्रिक व्यवस्था राज्य पुनःसंरचनासँग जोडिएका हिजोका सवालहरूलाई यथास्थितिमा छोडेर सबल होला?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08820a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding_sentence(input_sentence):\n",
    "    md = model\n",
    "    tokenizer = tokenizers\n",
    "#     md = local_model\n",
    "#     tokenizer = local_tokenizers\n",
    "    marked_text = \" [CLS] \" + input_sentence + \" [SEP] \"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(indexed_tokens) \n",
    "    \n",
    "    # Convert inputs to Pytorch tensors\n",
    "    tokens_tensors = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = md(tokens_tensors, segments_tensors)\n",
    "        # removing the first hidden state\n",
    "        # the first state is the input state \n",
    "\n",
    "        hidden_states = outputs.hidden_states\n",
    "#         print(hidden_states[-2])\n",
    "        # second_hidden_states = outputs[2]\n",
    "    # hidden_states has shape [13 x 1 x 22 x 768]\n",
    "\n",
    "    # token_vecs is a tensor with shape [22 x 768]\n",
    "#     token_vecs = hidden_states[-2][0]\n",
    "    # get last four layers\n",
    "#     last_four_layers = [hidden_states[i] for i in (-1,-2, -3,-4)]\n",
    "    # cast layers to a tuple and concatenate over the last dimension\n",
    "#     cat_hidden_states = torch.cat(tuple(last_four_layers), dim=-1)\n",
    "#     print(cat_hidden_states.shape)\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "    # take the mean of the concatenated vector over the token dimension\n",
    "#     sentence_embedding = torch.mean(cat_hidden_states, dim=0).squeeze()\n",
    "\n",
    "    # Calculate the average of all 22 token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "#     sentence_embedding = torch.mean(token_vecs, dim=1)\n",
    "    return sentence_embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c810fd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अमेरिकामा कोभिड बाट एकै दिन चार हजारभन्दा बढीको मृत्यु'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Tweet\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a1a2cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['word_embeddings'] = data['Tweet'].apply(get_bert_embedding_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acecae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"final_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d02329ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"word_embeddings\"][364].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16889493",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data['word_embeddings'], data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fad91b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a560a",
   "metadata": {},
   "source": [
    "train_df,test_df = train_test_split(data, test_size = 0.2, random_state = 420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4a917",
   "metadata": {},
   "source": [
    "train_df.to_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbff085",
   "metadata": {},
   "source": [
    "test_df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbcf42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "svm_grid = SVC()\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [1e-3, 1e-4]}\n",
    "\n",
    "svm_grid = GridSearchCV(svm_grid, param_grid=param_grid, cv=5, refit=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19002a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "svm_grid_fit = svm_grid.fit(train_X.tolist(), train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fe236ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.001)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f706ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=10, gamma=0.001,probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba420c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.001, probability=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(train_X.tolist(), train_y)\n",
    "#svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a4c4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = svc.predict(test_X.tolist())\n",
    "# svc_pred = svc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf9e1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2255   67  499]\n",
      " [ 287  528  484]\n",
      " [ 512   74 2374]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "614ae1ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.80      0.77      2821\n",
      "           0       0.79      0.41      0.54      1299\n",
      "           1       0.71      0.80      0.75      2960\n",
      "\n",
      "    accuracy                           0.73      7080\n",
      "   macro avg       0.74      0.67      0.69      7080\n",
      "weighted avg       0.73      0.73      0.72      7080\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7482e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One vs Rest Logisitic Regression accuracy =  0.7201977401129943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "ovr = OneVsRestClassifier(logreg)\n",
    "\n",
    "ovr.fit(train_X.tolist(), train_y)\n",
    "ovr_acc = ovr.score(test_X.tolist(), test_y)\n",
    "\n",
    "print(\"One vs Rest Logisitic Regression accuracy = \", ovr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ovr = LogisticRegression()\n",
    "\n",
    "param_grid = {'C': [1, 10, 100, 1000] }\n",
    "\n",
    "ovr_grid = GridSearchCV(ovr, param_grid=param_grid, cv=5, refit=True, verbose=1)\n",
    "ovr_grid_fit = ovr_grid.fit(train_X.tolist(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "368541f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB 0.5991525423728814\n",
      "CPU times: user 937 ms, sys: 1.64 s, total: 2.57 s\n",
      "Wall time: 647 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "'''\n",
    "    Naive Bayes BernoulliNB\n",
    "'''\n",
    "\n",
    "nb_bern_clf = BernoulliNB()\n",
    "nb_bern_clf.fit(X=train_X.tolist(), y=train_y)\n",
    "nb_bern_score = nb_bern_clf.score(test_X.tolist(), test_y)\n",
    "\n",
    "print('BernoulliNB', nb_bern_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a278d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier 0.6888418079096045\n",
      "CPU times: user 1min 13s, sys: 58.5 s, total: 2min 12s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    KNN Classifier\n",
    "'''\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X=train_X.tolist(), y=train_y)\n",
    "knn_score = knn_clf.score(test_X.tolist(), test_y)\n",
    "\n",
    "print('KNN Classifier', knn_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43c19a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Classifier 0.626412429378531\n",
      "CPU times: user 1.19 s, sys: 24.1 ms, total: 1.22 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Perceptron\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "percept = Perceptron(alpha=0.00001, tol=1e-5, penalty='l2', random_state=1, max_iter=1000)\n",
    "percept = percept.fit(X=train_X.tolist(), y=train_y)\n",
    "percept_score = percept.score(test_X.tolist(), test_y)\n",
    "\n",
    "print('Perceptron Classifier', percept_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae41dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayered Perceptron Classifier - lbfgs 0.6885593220338984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fm-pc-lt-228/anaconda3/envs/nepali/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_lbfgs = MLPClassifier(solver='lbfgs', alpha=1e-5, tol=1e-5,\n",
    "                    hidden_layer_sizes=(100, 50, 25), random_state=1,\n",
    "                   max_iter=1000)\n",
    "mlp_lbfgs.fit(X=train_X.tolist(), y=train_y)\n",
    "\n",
    "mlp_lbfgs_score = mlp_lbfgs.score(test_X.tolist(), test_y)\n",
    "\n",
    "print('MultiLayered Perceptron Classifier - lbfgs', mlp_lbfgs_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f62ae1f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'print_acc' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    Bagging Classifier\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagg = BaggingClassifier()\n",
    "\n",
    "\n",
    "\n",
    "bagg.fit(X=train_X.tolist(), y=train_y)\n",
    "\n",
    "bagg_score = bagg.score(test_X.tolist(), test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c00b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier 0.6639830508474577\n"
     ]
    }
   ],
   "source": [
    "print('Bagging Classifier', bagg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b92c88c2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'print_acc' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "    SGD Classifier\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(max_iter=2000, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "\n",
    "\n",
    "sgd.fit(X=train_X.tolist(), y=train_y)\n",
    "\n",
    "sgd_score = sgd.score(test_X.tolist(), test_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99a5fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier 0.7148305084745763\n"
     ]
    }
   ],
   "source": [
    "print('SGD Classifier', sgd_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e9efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
